# ==============================================================
# 6ë‹¨ê³„: ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ (ì‹¤ì „) ï¿½
# ==============================================================
# 
# ğŸ¯ ëª©í‘œ:
#    - ë„¤ì´ë²„ ë‰´ìŠ¤(IT/ê³¼í•™) ì„¹ì…˜ì˜ í—¤ë“œë¼ì¸ ë‰´ìŠ¤ ìˆ˜ì§‘
#    - ì œëª©, ë‚´ìš© ìš”ì•½, ì‹ ë¬¸ì‚¬, ë§í¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
#    - ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°
#
# ==============================================================

import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime

# --------------------------------------------------------------
# ğŸŒ 1. ì›¹ì‚¬ì´íŠ¸ ì ‘ì† (User-Agent ì„¤ì • í•„ìˆ˜!)
# --------------------------------------------------------------
url = "https://news.naver.com/section/105"  # IT/ê³¼í•™ ë‰´ìŠ¤

# ğŸš¨ ì¤‘ìš”: ë„¤ì´ë²„ ê°™ì€ ëŒ€í˜• í¬í„¸ì€ ë¡œë´‡(í”„ë¡œê·¸ë¨) ì ‘ì†ì„ ë§‰ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# "ë‚˜ëŠ” ë¡œë´‡ì´ ì•„ë‹ˆë¼ ë¸Œë¼ìš°ì €ì•¼!"ë¼ê³  ì•Œë ¤ì£¼ê¸° ìœ„í•´ User-Agent ì •ë³´ë¥¼ í•¨ê»˜ ë³´ëƒ…ë‹ˆë‹¤.
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

print(f"ğŸŒ ë„¤ì´ë²„ ë‰´ìŠ¤ì— ì ‘ì† ì¤‘... ({url})")
response = requests.get(url, headers=headers)

# ì ‘ì† í™•ì¸
if response.status_code != 200:
    print(f"âŒ ì ‘ì† ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {response.status_code}")
    exit()

# --------------------------------------------------------------
# ğŸ¥£ 2. HTML ë¶„ì„ ì¤€ë¹„
# --------------------------------------------------------------
soup = BeautifulSoup(response.text, "html.parser")

# --------------------------------------------------------------
# ï¿½ 3. ë‰´ìŠ¤ ë°ì´í„° ì°¾ê¸°
# --------------------------------------------------------------
print("ğŸ” ë‰´ìŠ¤ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")

# ë°ì´í„°ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
news_list = []

# ë„¤ì´ë²„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ì°¾ê¸°
# ì‚¬ìš©ìê°€ ì œê³µí•œ íŒíŠ¸: <li class="sa_item _SECTION_HEADLINE">
news_items = soup.select("li.sa_item")

print(f"ì´ {len(news_items)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

for item in news_items:
    try:
        # 1) ë‰´ìŠ¤ ì œëª© (strong class="sa_text_strong")
        title_tag = item.select_one("strong.sa_text_strong")
        if not title_tag: continue  # ì œëª©ì´ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
        title = title_tag.text.strip()

        # 2) ë‰´ìŠ¤ ë‚´ìš© ìš”ì•½ (div class="sa_text_lede")
        summary_tag = item.select_one("div.sa_text_lede")
        summary = summary_tag.text.strip() if summary_tag else "ìš”ì•½ ì—†ìŒ"

        # 3) ì‹ ë¬¸ì‚¬ (div class="sa_text_press")
        press_tag = item.select_one("div.sa_text_press")
        press = press_tag.text.strip() if press_tag else "ì•Œ ìˆ˜ ì—†ìŒ"

        # 4) ë‰´ìŠ¤ ë§í¬ (a class="sa_text_title")ì˜ href ì†ì„±
        link_tag = item.select_one("a.sa_text_title")
        link = link_tag["href"] if link_tag else ""

        # ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ê¸°
        news_data = {
            "ë‰´ìŠ¤ ì œëª©": title,
            "ë‰´ìŠ¤ ë‚´ìš©": summary,
            "ì‹ ë¬¸ì‚¬": press,
            "ë§í¬": link
        }
        
        # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        news_list.append(news_data)
        
        # í™•ì¸ìš© ì¶œë ¥ (ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬)
        # print(f"- {title} ({press})")

    except Exception as e:
        print(f"âš ï¸ ì—ëŸ¬ ë°œìƒ: {e}")
        continue

print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(news_list)}ê°œ")

# --------------------------------------------------------------
# ï¿½ 4. ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°
# --------------------------------------------------------------
# ì˜¤ëŠ˜ ë‚ ì§œ êµ¬í•˜ê¸°
today = datetime.now()
date_str = today.strftime("%Y_%m_%d")

# íŒŒì¼ ì´ë¦„: naver_news_2026_01_21.xlsx
file_name = f"naver_news_{date_str}.xlsx"

print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì¤‘... ({file_name})")

# ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì €ì¥
df = pd.DataFrame(news_list)
df.to_excel(file_name, index=False)

print("ğŸ‰ ì €ì¥ ì™„ë£Œ!")
